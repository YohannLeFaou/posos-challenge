{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset # used load data\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers.data.processors.utils import InputExample, InputFeatures\n",
    "from transformers import (AdamW,\n",
    "                          get_linear_schedule_with_warmup,\n",
    "                          get_cosine_with_hard_restarts_schedule_with_warmup)\n",
    "\n",
    "from transformers import (CamembertConfig,\n",
    "                          CamembertForSequenceClassification,\n",
    "                          CamembertTokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data=\"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(path_data + \"input_train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(path_data + \"output_train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(path_data + \"input_test_b1Yip6O.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "    \n",
    "class DataProcessor():\n",
    "    \n",
    "    def get_data_examples(self, sentences, labels=None):\n",
    "        examples = []\n",
    "        guid = \"data\"\n",
    "        if labels is None:\n",
    "            for i in range(len(sentences)):\n",
    "                examples.append(InputExample(guid=guid, text_a=sentences[i], text_b=None, label=\"0\"))\n",
    "        else:\n",
    "            for i in range(len(sentences)):\n",
    "                examples.append(InputExample(guid=guid, text_a=sentences[i], text_b=None, label=str(labels[i])))\n",
    "            \n",
    "        return examples\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [str(j) for j in range(51)]\n",
    "\n",
    "    \n",
    "def convert_examples_to_features(examples,\n",
    "                                 tokenizer,\n",
    "                                 max_length=512,\n",
    "                                 label_list=None,\n",
    "                                 pad_on_left=False,\n",
    "                                 pad_token=0,\n",
    "                                 pad_token_segment_id=0,\n",
    "                                 mask_padding_with_zero=True):\n",
    "\n",
    "    processor = DataProcessor()\n",
    "\n",
    "    label_map = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            example.text_a,\n",
    "            example.text_b,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "        input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding_length = max_length - len(input_ids)\n",
    "        if pad_on_left:\n",
    "            input_ids = ([pad_token] * padding_length) + input_ids\n",
    "            attention_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + attention_mask\n",
    "            token_type_ids = ([pad_token_segment_id] * padding_length) + token_type_ids\n",
    "        else:\n",
    "            input_ids = input_ids + ([pad_token] * padding_length)\n",
    "            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)\n",
    "\n",
    "        assert len(input_ids) == max_length, \"Error with input length {} vs {}\".format(len(input_ids), max_length)\n",
    "        assert len(attention_mask) == max_length, \"Error with input length {} vs {}\".format(len(attention_mask), max_length)\n",
    "        assert len(token_type_ids) == max_length, \"Error with input length {} vs {}\".format(len(token_type_ids), max_length)\n",
    "        \n",
    "        label = label_map[example.label]\n",
    "        \n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              attention_mask=attention_mask,\n",
    "                              token_type_ids=token_type_ids,\n",
    "                              label=label))\n",
    "\n",
    "    return features\n",
    "\n",
    "def load_examples(sentences,\n",
    "                            labels,\n",
    "                            tokenizer, \n",
    "                            max_seq_length,\n",
    "                            label_list):\n",
    " \n",
    "    processor = DataProcessor()\n",
    "    examples = processor.get_data_examples(sentences, labels)\n",
    "\n",
    "    features = convert_examples_to_features(examples,\n",
    "                                            tokenizer,\n",
    "                                            label_list=label_list,\n",
    "                                            max_length=max_seq_length,\n",
    "                                            pad_on_left=False,\n",
    "                                            pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
    "                                            pad_token_segment_id=0,\n",
    "    )\n",
    "\n",
    "    # Convert to Tensors and build dataset\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
    "    all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n",
    "    all_labels = torch.tensor([f.label for f in features], dtype=torch.long)\n",
    "\n",
    "    dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataset, tokenizer, num_train_epochs, train_batch_size, learning_rate, adam_epsilon=1e-8,\n",
    "          logging_steps=None, gradient_accumulation_steps=1, max_grad_norm=1.0, weight_decay=0.0,\n",
    "          warmup_steps=0, save_steps=-1, output_dir=None, evaluate_during_training=False,\n",
    "          seed=None, max_steps=-1, num_cycles=1.0, eval_dataset = None, verbose=0):\n",
    "    \n",
    "    \"\"\" Train the model \"\"\"\n",
    "    \n",
    "    assert not(logging_steps > 0 and eval_dataset is None), \"logging_steps > 0 but no eval_dataset provided\"\n",
    "    \n",
    "    if output_dir is None and save_steps > 0:\n",
    "        output_dir = \"model_\" + str(datetime.datetime.now()).split(\".\")[0].replace(\" \",\"_\") + \"/\"\n",
    "        \n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=train_batch_size)\n",
    "    \n",
    "    if logging_steps is None:\n",
    "        logging_steps = len(train_dataloader) // (gradient_accumulation_steps * 5)\n",
    "        \n",
    "    if max_steps > 0:\n",
    "        t_total = max_steps\n",
    "        num_train_epochs = max_steps // (len(train_dataloader) // gradient_accumulation_steps) + 1\n",
    "    else:\n",
    "        t_total = len(train_dataloader) // gradient_accumulation_steps * num_train_epochs\n",
    "\n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    \n",
    "    # pas besoin de la partie custom ci-dessous à priori\n",
    "    \n",
    "    #no_decay = ['bias', 'LayerNorm.weight']\n",
    "    #optimizer_grouped_parameters = [\n",
    "    #    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
    "    #    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    #    ]\n",
    "    \n",
    "    # change l'optimizer pour voir\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon) # optimizer_grouped_parameters\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9) #eps=adam_epsilon , momentum=0.9\n",
    "    #scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total)\n",
    "    scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer,\n",
    "                                                                   num_warmup_steps=warmup_steps,\n",
    "                                                                   num_training_steps=t_total,\n",
    "                                                                   num_cycles=num_cycles)\n",
    "    #for i, tensor in enumerate(model.parameters()):\n",
    "    #    if i > 1:\n",
    "    #        tensor.requires_grad = False\n",
    "\n",
    "    # Train!\n",
    "    print(\"***** Running training *****\")\n",
    "    print(\"  Num examples = %d\" % len(train_dataset))\n",
    "    print(\"  Num Epochs = %d\" % num_train_epochs)\n",
    "    print(\" Batch size = %d\" % train_batch_size)\n",
    "    print(\"  Total train batch size (w. parallel, distributed & accumulation) = %d\" %\n",
    "                   train_batch_size * gradient_accumulation_steps)\n",
    "    print(\"  Gradient Accumulation steps = %d\" % gradient_accumulation_steps)\n",
    "    print(\"  Total optimization steps = %d\" % t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(int(num_train_epochs), desc=\"Epoch\")\n",
    "    if seed is not None:\n",
    "        set_seed(seed)\n",
    "        \n",
    "    for epoch, _ in enumerate(train_iterator):\n",
    "        # print(\"Epoch %d / %d\" % (epoch, num_train_epochs))\n",
    "        epoch_iterator = train_dataloader\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            model.train()\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'labels':         batch[3]}\n",
    "            inputs['token_type_ids'] = batch[2] #or None\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            #print(outputs)\n",
    "            #print(outputs[0].size())\n",
    "            #print(outputs[1].size())\n",
    "            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
    "            #print(loss)\n",
    "            \n",
    "            if gradient_accumulation_steps > 1:\n",
    "                loss = loss / gradient_accumulation_steps\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if verbose > 0:\n",
    "                print(\"lr:\",scheduler.get_lr()[0], \"loss:\", loss.item())\n",
    "                \n",
    "            if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "                if logging_steps > 0 and global_step % logging_steps == 0:\n",
    "                    if verbose > 0:\n",
    "                        print(\"\\nEval\")\n",
    "                    # Log metrics\n",
    "                    dict_print = {'step':global_step,\n",
    "                                  'lr': scheduler.get_lr()[0],\n",
    "                                  'tr_loss': (tr_loss - logging_loss)/logging_steps}\n",
    "                    if evaluate_during_training:\n",
    "                        results = evaluate(model=model, eval_dataset=eval_dataset,\n",
    "                                           tokenizer=tokenizer, eval_output_dir=output_dir,\n",
    "                                           verbose=verbose)\n",
    "                        for key, value in results.items():\n",
    "                            dict_print['eval_{}'.format(key)] = value\n",
    "                    print(dict_print)\n",
    "                    logging_loss = tr_loss\n",
    "\n",
    "                if save_steps > 0 and global_step % save_steps == 0:\n",
    "                    # Save model checkpoint\n",
    "                    if not os.path.exists(output_dir):\n",
    "                        os.makedirs(output_dir)\n",
    "                    save_model_dir = os.path.join(output_dir, 'checkpoint-{}'.format(global_step))\n",
    "                    os.makedirs(save_model_dir)\n",
    "                    model.save_pretrained(save_model_dir)\n",
    "                    #torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n",
    "                    print(\"Saving model checkpoint to %s\" % save_model_dir)\n",
    "\n",
    "            if max_steps > 0 and global_step > max_steps:\n",
    "                #epoch_iterator.close() #deleted since no tqdm anymore\n",
    "                break\n",
    "                \n",
    "        if max_steps > 0 and global_step > max_steps:\n",
    "            train_iterator.close()\n",
    "            break\n",
    "\n",
    "    if global_step == 0:\n",
    "        global_step= 1\n",
    "\n",
    "    return global_step, tr_loss / global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, eval_dataset, tokenizer, eval_batch_size=8, prefix=\"\", eval_output_dir=None,\n",
    "             verbose=1):\n",
    "        \n",
    "    eval_batch_size = eval_batch_size\n",
    "    # Note that DistributedSampler samples randomly\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=eval_batch_size)\n",
    "    \n",
    "    # Eval!\n",
    "    if verbose > 0:\n",
    "        print(\"***** Running evaluation {} *****\".format(prefix))\n",
    "        print(\"  Num examples = %d\", len(eval_dataset))\n",
    "        print(\"  Batch size = %d\", eval_batch_size)\n",
    "        \n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    iterator = tqdm(eval_dataloader, desc=\"Evaluating\") if verbose > 0 else eval_dataloader\n",
    "    \n",
    "    for batch in iterator:\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'labels':         batch[3]}\n",
    "            inputs['token_type_ids'] = batch[2] #or None\n",
    "            outputs = model(**inputs)\n",
    "            tmp_eval_loss, logits = outputs[:2]\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    preds_class = np.argmax(preds, axis=1)\n",
    "    acc = accuracy_score(out_label_ids, preds_class)\n",
    "    \n",
    "    result = {\"val_loss\": eval_loss, \"val_acc\" : acc}\n",
    "    #results.update(result)\n",
    "\n",
    "    if eval_output_dir is not None:\n",
    "        if not os.path.exists(eval_output_dir):\n",
    "            os.makedirs(eval_output_dir)\n",
    "        \n",
    "        output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n",
    "        with open(output_eval_file, \"a\") as writer:\n",
    "            writer.write(\"***** Eval results {} *****\".format(prefix))\n",
    "            for key in sorted(result.keys()):\n",
    "                writer.write(\"  %s = %s\" % (key, str(result[key])))\n",
    "            writer.write(\"\\n\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataset, batch_size, verbose=1):\n",
    "    \n",
    "    # Note that DistributedSampler samples randomly\n",
    "    sampler = SequentialSampler(dataset)\n",
    "    dataloader = DataLoader(dataset, sampler=sampler, batch_size=batch_size)\n",
    "\n",
    "    # Eval!\n",
    "    if verbose > 0:\n",
    "        print(\"***** Running prediction *****\")\n",
    "        print(\"  Num examples = %d\", len(dataset))\n",
    "        print(\"  Batch size = %d\", batch_size)\n",
    "\n",
    "    loss = 0.0\n",
    "    nb_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    iterator = tqdm(dataloader, desc=\"Predict\") if verbose > 0 else dataloader\n",
    "    \n",
    "    for batch in iterator:\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'labels':         batch[3]}\n",
    "            inputs['token_type_ids'] = batch[2] #or None\n",
    "            outputs = model(**inputs)\n",
    "            tmp_eval_loss, logits = outputs[:2]\n",
    "            loss += tmp_eval_loss.mean().item()\n",
    "        nb_steps += 1\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    loss = loss / nb_steps\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels=51\n",
    "model_name=\"camembert-base\"\n",
    "\n",
    "config = CamembertConfig.from_pretrained(model_name,\n",
    "                                         num_labels=num_labels,\n",
    "                                         finetuning_task=\"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CamembertTokenizer.from_pretrained(model_name,\n",
    "                                               do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CamembertForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_val, labels_train, labels_val = train_test_split(df_train[\"question\"].values,\n",
    "                                                                            df_labels[\"intention\"].values,\n",
    "                                                                            test_size=0.2,\n",
    "                                                                            random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example 0\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_examples(sentences=sentences_train,\n",
    "                                  labels=labels_train,\n",
    "                                  tokenizer=tokenizer,\n",
    "                                  max_seq_length = 128,\n",
    "                                  label_list = [str(j) for j in range(num_labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example 0\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = load_examples(sentences=sentences_val,\n",
    "                                  labels=labels_val,\n",
    "                                  tokenizer=tokenizer,\n",
    "                                  max_seq_length = 128,\n",
    "                                  label_list = [str(j) for j in range(num_labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 6422\n",
      "  Num Epochs = 1\n",
      " Batch size = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e564615b64e4bb3a4588b65edc0d4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Eval\n",
      "{'step': 2, 'lr': 2.2500000000000015e-05, 'tr_loss': 3.9270644187927246, 'eval_val_loss': 3.9023621568632363, 'eval_val_acc': 0.02054794520547945}\n",
      "\n",
      "\n",
      "Eval\n",
      "{'step': 4, 'lr': 0.0, 'tr_loss': 3.9058990478515625, 'eval_val_loss': 3.8899942262848812, 'eval_val_acc': 0.08468244084682441}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 3.9164817333221436)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model=model, train_dataset=train_dataset, tokenizer=tokenizer, train_batch_size=32,\n",
    "      learning_rate=3e-5, num_train_epochs=10, evaluate_during_training=True, logging_steps=2,\n",
    "      max_grad_norm=1.0, save_steps=-1, num_cycles=5.0, max_steps=3, eval_dataset=eval_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CamembertForSequenceClassification.from_pretrained(\"model_2019-12-08_14:59:37/checkpoint-400/checkpoint-800/checkpoint-1200/\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features from cached file data/cached_test_128\n",
      "***** Running evaluation  *****\n",
      "  Num examples = %d 1606\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1f31e9dc9541e1a846ff11112f9400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=201, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 1.5273962446409672, 'val_acc': 0.6749688667496887}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, eval_dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on test set and build submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example 0\n"
     ]
    }
   ],
   "source": [
    "test_dataset = load_examples(sentences=df_test[\"question\"],\n",
    "                                  labels=None,\n",
    "                                  tokenizer=tokenizer,\n",
    "                                  max_seq_length = 128,\n",
    "                                  label_list = [str(j) for j in range(51)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "  Num examples = %d 2035\n",
      "  Batch size = %d 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4475a52058e44f488e29bd2cf62a97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Predict', max=255, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds_test = predict(model=model,\n",
    "                     dataset=test_dataset,\n",
    "                     batch_size = 8)\n",
    "preds_class_test = np.argmax(preds_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({\"ID\": df_test[\"ID\"].values,  \"intention\": preds_class_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>intention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8028</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8029</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8030</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8031</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8032</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  intention\n",
       "0  8028         32\n",
       "1  8029         32\n",
       "2  8030         32\n",
       "3  8031         31\n",
       "4  8032         44"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"sub/sub0.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
